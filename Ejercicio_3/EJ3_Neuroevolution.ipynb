{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne7Uo3jPe4lQ"
      },
      "outputs": [],
      "source": [
        "!pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from copy import deepcopy\n",
        "from functools import partial\n",
        "import multiprocessing\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from deap import base, creator, tools, algorithms\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "OvU1xxfxfVV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "POP_SIZE = 20\n",
        "GENERATIONS = 12\n",
        "CX_PB = 0.6\n",
        "MUT_PB = 0.3\n",
        "N_JOBS = max(1, multiprocessing.cpu_count() - 1)\n",
        "EPOCHS = 25\n",
        "BATCH_OPTIONS = [16, 32, 64]\n",
        "LR_OPTIONS = [1e-3, 5e-4, 1e-4]\n",
        "ACTIVATIONS = ['relu', 'tanh', 'elu']\n",
        "NEURON_CHOICES = [8, 16, 32, 64, 128, 256]\n",
        "MAX_HIDDEN_LAYERS = 3"
      ],
      "metadata": {
        "id": "USm3sq9EfVTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_optional_csv(csv_path=None, target_col=None):\n",
        "    if csv_path is None:\n",
        "        d = load_breast_cancer()\n",
        "        X = d.data\n",
        "        y = d.target\n",
        "        feature_names = d.feature_names\n",
        "        return X, y, feature_names\n",
        "    else:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if target_col is None:\n",
        "            raise ValueError(\"Si subes CSV debes proveer target_col (nombre de columna objetivo).\")\n",
        "        y = df[target_col].values\n",
        "        X = df.drop(columns=[target_col]).values\n",
        "        feature_names = df.drop(columns=[target_col]).columns.values\n",
        "        return X, y, feature_names"
      ],
      "metadata": {
        "id": "4oeb2b9tfVQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = None\n",
        "target_col = None\n",
        "X, y, feature_names = load_data_from_optional_csv(csv_path, target_col)\n",
        "\n",
        "# Train/Validation/Test split\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, random_state=SEED, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1765, random_state=SEED, stratify=y_trainval)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "INPUT_DIM = X_train.shape[1]\n",
        "N_CLASSES = 1 if len(np.unique(y)) == 2 else len(np.unique(y))\n",
        "\n",
        "print(\"Dataset shape: X_train\", X_train.shape, \"X_val\", X_val.shape, \"X_test\", X_test.shape)\n",
        "print(\"Input dim:\", INPUT_DIM)"
      ],
      "metadata": {
        "id": "W-1VhPD_fVOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DROPOUT_OPTIONS = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "EPOCHS_OPTIONS = [8, 12, 25, 40]\n",
        "\n",
        "IND_SIZE = 1 + MAX_HIDDEN_LAYERS + 1 + 1 + 1 + 1 + 1\n",
        "\n",
        "\n",
        "def decode_individual(ind):\n",
        "    n_hidden = int(ind[0])\n",
        "    neurons_idx = ind[1:1+MAX_HIDDEN_LAYERS]\n",
        "    neurons = [NEURON_CHOICES[int(i)] for i in neurons_idx[:n_hidden]]\n",
        "    act = ACTIVATIONS[int(ind[1+MAX_HIDDEN_LAYERS])]\n",
        "    dropout = DROPOUT_OPTIONS[int(ind[2+MAX_HIDDEN_LAYERS])]\n",
        "    lr = LR_OPTIONS[int(ind[3+MAX_HIDDEN_LAYERS])]\n",
        "    batch = BATCH_OPTIONS[int(ind[4+MAX_HIDDEN_LAYERS])]\n",
        "    epochs_eval = int(EPOCHS_OPTIONS[int(ind[5+MAX_HIDDEN_LAYERS])])\n",
        "    return {\n",
        "        'n_hidden': n_hidden,\n",
        "        'neurons': neurons,\n",
        "        'activation': act,\n",
        "        'dropout': dropout,\n",
        "        'lr': lr,\n",
        "        'batch': batch,\n",
        "        'epochs_eval': epochs_eval\n",
        "    }\n",
        "\n",
        "def build_model_from_genome(genome):\n",
        "    K.clear_session()\n",
        "    model = Sequential()\n",
        "    if genome['n_hidden'] == 0:\n",
        "        if N_CLASSES == 1:\n",
        "            model.add(Dense(1, input_dim=INPUT_DIM, activation='sigmoid'))\n",
        "        else:\n",
        "            model.add(Dense(N_CLASSES, input_dim=INPUT_DIM, activation='softmax'))\n",
        "        return model\n",
        "    model.add(Dense(genome['neurons'][0], input_dim=INPUT_DIM, activation=genome['activation']))\n",
        "    if genome['dropout'] > 0:\n",
        "        model.add(Dropout(genome['dropout']))\n",
        "    for n in genome['neurons'][1:]:\n",
        "        model.add(Dense(n, activation=genome['activation']))\n",
        "        if genome['dropout'] > 0:\n",
        "            model.add(Dropout(genome['dropout']))\n",
        "    if N_CLASSES == 1:\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "    else:\n",
        "        model.add(Dense(N_CLASSES, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "def evaluate_individual(individual, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val):\n",
        "    genome = decode_individual(individual)\n",
        "    model = build_model_from_genome(genome)\n",
        "    optimizer = Adam(learning_rate=genome['lr'])\n",
        "    if N_CLASSES == 1:\n",
        "        loss = 'binary_crossentropy'\n",
        "        metrics = ['accuracy']\n",
        "    else:\n",
        "        loss = 'sparse_categorical_crossentropy'\n",
        "        metrics = ['accuracy']\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "    es = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True, verbose=0)\n",
        "    try:\n",
        "        history = model.fit(X_train, y_train,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            epochs=genome['epochs_eval'],\n",
        "                            batch_size=genome['batch'],\n",
        "                            callbacks=[es],\n",
        "                            verbose=0)\n",
        "        val_metrics = model.evaluate(X_val, y_val, verbose=0)\n",
        "        val_acc = val_metrics[1] if len(val_metrics) > 1 else val_metrics[0]\n",
        "    except Exception as e:\n",
        "        print(\"Error entrenando individuo:\", e)\n",
        "        val_acc = 0.0\n",
        "    K.clear_session()\n",
        "    return (float(val_acc),)\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"n_hidden_attr\", random.randint, 1, MAX_HIDDEN_LAYERS)\n",
        "toolbox.register(\"neuron_attr\", random.randrange, 0, len(NEURON_CHOICES))\n",
        "toolbox.register(\"act_attr\", random.randrange, 0, len(ACTIVATIONS))\n",
        "toolbox.register(\"dropout_attr\", random.randrange, 0, len(DROPOUT_OPTIONS))\n",
        "toolbox.register(\"lr_attr\", random.randrange, 0, len(LR_OPTIONS))\n",
        "toolbox.register(\"batch_attr\", random.randrange, 0, len(BATCH_OPTIONS))\n",
        "toolbox.register(\"epochattr\", random.randrange, 0, len(EPOCHS_OPTIONS))\n",
        "\n",
        "def create_individual():\n",
        "    ind = []\n",
        "    ind.append(toolbox.n_hidden_attr())\n",
        "    for _ in range(MAX_HIDDEN_LAYERS):\n",
        "        ind.append(toolbox.neuron_attr())\n",
        "    ind.append(toolbox.act_attr())\n",
        "    ind.append(toolbox.dropout_attr())\n",
        "    ind.append(toolbox.lr_attr())\n",
        "    ind.append(toolbox.batch_attr())\n",
        "    ind.append(toolbox.epochattr())\n",
        "    return creator.Individual(ind)\n",
        "toolbox.register(\"individual\", create_individual)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)"
      ],
      "metadata": {
        "id": "PK-VDoOofVLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mutate_architecture(individual, indpb=0.2):\n",
        "    if random.random() < indpb:\n",
        "        individual[0] = random.randint(1, MAX_HIDDEN_LAYERS)\n",
        "    for i in range(1, 1 + MAX_HIDDEN_LAYERS):\n",
        "        if random.random() < indpb:\n",
        "            individual[i] = random.randrange(0, len(NEURON_CHOICES))\n",
        "    if random.random() < indpb:\n",
        "        individual[1 + MAX_HIDDEN_LAYERS] = random.randrange(0, len(ACTIVATIONS))\n",
        "    if random.random() < indpb:\n",
        "        individual[2 + MAX_HIDDEN_LAYERS] = random.randrange(0, len(DROPOUT_OPTIONS))\n",
        "    if random.random() < indpb:\n",
        "        individual[3 + MAX_HIDDEN_LAYERS] = random.randrange(0, len(LR_OPTIONS))\n",
        "    if random.random() < indpb:\n",
        "        individual[4 + MAX_HIDDEN_LAYERS] = random.randrange(0, len(BATCH_OPTIONS))\n",
        "    if random.random() < indpb:\n",
        "        individual[5 + MAX_HIDDEN_LAYERS] = random.randrange(0, len(EPOCHS_OPTIONS))\n",
        "    return (individual,)\n",
        "toolbox.register(\"mutate\", mutate_architecture, indpb=0.25)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "def evaluate_pool_wrapper(individual):\n",
        "    return evaluate_individual(individual)\n",
        "\n",
        "def run_ga(pop_size=POP_SIZE, gens=GENERATIONS, cxpb=CX_PB, mutpb=MUT_PB, n_jobs=N_JOBS):\n",
        "    pop = toolbox.population(n=pop_size)\n",
        "    if n_jobs and n_jobs > 1:\n",
        "        pool = multiprocessing.Pool(processes=n_jobs)\n",
        "        toolbox.register(\"map\", pool.map)\n",
        "    else:\n",
        "        pool = None\n",
        "    toolbox.register(\"evaluate\", evaluate_pool_wrapper)\n",
        "    hall_of_fame = tools.HallOfFame(3)\n",
        "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "    stats.register(\"avg\", np.mean)\n",
        "    stats.register(\"std\", np.std)\n",
        "    stats.register(\"min\", np.min)\n",
        "    stats.register(\"max\", np.max)\n",
        "    logbook = tools.Logbook()\n",
        "    logbook.header = [\"gen\", \"nevals\"] + stats.fields\n",
        "    start_time = time()\n",
        "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=cxpb, mutpb=mutpb,\n",
        "                                   ngen=gens, stats=stats, halloffame=hall_of_fame, verbose=True)\n",
        "    elapsed = time() - start_time\n",
        "    if pool is not None:\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "    return pop, log, hall_of_fame, elapsed"
      ],
      "metadata": {
        "id": "NBigUl9vfY3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Iniciando GA con pop_size\", POP_SIZE, \"generations\", GENERATIONS, \"n_jobs\", N_JOBS)\n",
        "pop, log, hof, elapsed = run_ga()\n",
        "print(\"GA terminado en {:.1f}s\".format(elapsed))\n",
        "\n",
        "best = hof[0]\n",
        "best_genome = decode_individual(best)\n",
        "print(\"Mejor genoma encontrado:\\n\", best_genome)\n",
        "\n",
        "# Reentrenar mejor modelo en TRAIN+VAL combinado con más epochs\n",
        "X_full_train = np.vstack([X_train, X_val])\n",
        "y_full_train = np.hstack([y_train, y_val])\n",
        "\n",
        "final_model = build_model_from_genome(best_genome)\n",
        "optimizer = Adam(learning_rate=best_genome['lr'])\n",
        "if N_CLASSES == 1:\n",
        "    final_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "else:\n",
        "    final_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "es_final = EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True, verbose=1)\n",
        "history_final = final_model.fit(X_full_train, y_full_train,\n",
        "                                validation_split=0.1,\n",
        "                                epochs=80,\n",
        "                                batch_size=best_genome['batch'],\n",
        "                                callbacks=[es_final],\n",
        "                                verbose=1)\n",
        "\n",
        "# Evaluación final en test set\n",
        "y_pred_prob = final_model.predict(X_test)\n",
        "if N_CLASSES == 1:\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "else:\n",
        "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "print(\"\\nAccuracy final en test:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report (test):\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix (test):\\n\", confusion_matrix(y_test, y_pred))\n",
        "s\n",
        "os.makedirs(\"neuroevo_results\", exist_ok=True)\n",
        "final_model.save(\"neuroevo_results/best_model.h5\")\n",
        "pd.DataFrame(log).to_csv(\"neuroevo_results/logbook.csv\", index=False)\n",
        "with open(\"neuroevo_results/best_genome.txt\", \"w\") as f:\n",
        "    f.write(str(best_genome))\n",
        "\n",
        "# Plot training history final\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history_final.history['accuracy'], label='train_acc')\n",
        "plt.plot(history_final.history['val_accuracy'], label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training history - best model (final retrain)')\n",
        "plt.show()\n",
        "\n",
        "# Plot GA log (max fitness per generation)\n",
        "gens = [entry['gen'] for entry in log]\n",
        "maxs = [entry['max'] for entry in log]\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(gens, maxs, marker='o')\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Max fitness (val acc)')\n",
        "plt.title('GA progress')\n",
        "plt.show()\n",
        "\n",
        "print(\"Resultados guardados en ./neuroevo_results/\")"
      ],
      "metadata": {
        "id": "nwaXEf5TfY0y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}